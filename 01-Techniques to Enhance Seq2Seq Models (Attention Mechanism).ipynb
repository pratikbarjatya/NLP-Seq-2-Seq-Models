{"nbformat":4,"nbformat_minor":0,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"01-Techniques to Enhance Seq2Seq Models (Attention Mechanism).ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S37hyB85ih-u"},"source":["<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"360\" height=\"160\" /></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rRfn02fTwWM0"},"source":["# <center>Techniques to Enhance Seq2Seq Models (Attention Mechanism)</center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2rYEv9kJwWM1"},"source":["## Table of Contents\n","\n","1. [Techniques to Enhance Seq2Seq Models](#section1)<br><br>\n","2. [Attention Mechanism](#section2)<br><br>\n","3. [Implementing Attention Mechanism](#section3)<br><br>\n","4. [Conclusion](#section4)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"G445ZUWfwWM1"},"source":["<a id=section1></a>\n","## 1. Techniques to Enhance Seq2Seq Models"]},{"cell_type":"markdown","metadata":{"id":"ADGq3kJWmx4g","colab_type":"text"},"source":["Most **Neural Machine Translation (NMT)** systems work by *encoding* the **source sentence** (e.g. a *German sentence*) *into a vector using* a **Recurrent Neural Network**, and *then decoding* an *English sentence* based on that **vector**, also using a **RNN**.\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/nmt.png\"/></center>\n","\n","<br> \n","In the picture above, **“Echt”**, **“Dicke”** and **“Kiste” words** are *fed into* an *encoder*, and after a special signal the *decoder starts producing* a **translated sentence**. \n","\n","- The *decoder keeps generating words until* a *special end of sentence token* is **produced**.\n","\n","- Here, the **$h$ vectors** represent the **internal state** of the *encoder*.\n","\n","<br> \n","If you look closely, you can see that the *decoder* is *supposed to generate* a *translation solely based* on the **last hidden state** (**$h_{3}$** above) from the *encoder*. \n","\n","- This **$h_{3}$ vector** must *encode everything* we need to know about the **source sentence**. \n","\n","- *It must fully capture its meaning*. \n","\n","- In more technical terms, that **vector** is a **sentence embedding**.\n","\n","<br> \n","\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"P_GGOgZwCNUe"},"source":["Still, it seems somewhat unreasonable to assume that we can *encode all information about* a potentially *very long sentence into* a **single vector** and then have the *decoder produce* a *good translation based on only that*. \n","\n","Let’s say your **source sentence** is **50** words long. \n","\n"," - The *first word* of the **English translation** is probably **highly correlated** with the *first word* of the **source sentence**. \n"," \n"," - *But that means decoder* has to *consider information from 50 steps ago*, and *that information needs* to be somehow *encoded in* the **vector**. \n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/context_vector.png\"/></center>\n","\n","<br> \n","**Recurrent Neural Networks** are known to *have problems dealing with* such **long-range dependencies**. \n","\n","In theory, architectures like **LSTMs** should be able to *deal with this*, *but in practice long-range dependencies are* still **problematic**."]},{"cell_type":"markdown","metadata":{"id":"VXE9kpDbmx4i","colab_type":"text"},"source":["<a id=section2></a>\n","### 2. Attention Mechanism"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-C-5xa11zwSE"},"source":["With an **attention mechanism** we no longer try *encode the full source sentence into a fixed-length vector*. \n","\n","Rather, we **allow** the *decoder* to “**attend**” to *different parts of the source sentence at each step of the output generation*. \n","\n","Importantly, we let the *model learn what to attend* to *based on the input sentence* and *what it has produced* so far. \n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/attention_mechanism.png\"/></center>"]},{"cell_type":"markdown","metadata":{"id":"go3EoovHmx4j","colab_type":"text"},"source":["- Here, The **$y$‘s** are our *translated words produced by* the *decoder*, and the **$x$‘s** are our *source sentence words*. \n","\n","- *Each decoder output word* **$y_{t}$** now *depends on* a **weighted combination** of *all* the *input states*, *not just* the *last state*. \n","\n","- The **$\\alpha$‘s** are **weights** that *define how much* of *each input state* should be *considered for each output*. \n","\n","  - So, **if $\\alpha_{1,2}$** is a **large number**, this would *mean that* the *decoder pays* a *lot of attention to* the *second state in* the *source sentence while producing* the *first word of* the *target sentence*. \n","\n","  - The **$\\alpha$'s** are typically **normalized to sum to 1** (so they *are a distribution over* the *input states*)."]},{"cell_type":"markdown","metadata":{"id":"LQqHfHBTmx4k","colab_type":"text"},"source":["<a id=section3></a>\n","### 3. Implementing Attention Mechanism"]},{"cell_type":"markdown","metadata":{"id":"rrdNOuR_mx4l","colab_type":"text"},"source":["The **implementations** of an **attention layer** can be broken down into **4 steps**.\n","\n","<br>\n","\n","**Step 0: Prepare hidden states.**\n","\n","Let’s *first prepare all* the *available encoder hidden states* (**green**) and the *first decoder hidden state* (**red**). \n","\n","In our example, we have *4 encoder hidden states* and the *current decoder hidden state*. \n","\n","<br> \n","Note: The *last consolidated encoder hidden state* is **fed as input to** the *first time step of* the *decoder*. \n","\n","The *output of* this *first time step of* the *decoder* is *called* the **first decoder hidden state**, as seen below.\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/attention_mechanism0.gif\"/></center>\n","\n","<br>\n","<center><strong>Fig. 1.0: Getting ready to pay attention</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"DuLw9YA0mx4l","colab_type":"text"},"source":["**Step 1: Obtain a score for every encoder hidden state.**\n","\n","A **score** (**scalar**) is *obtained by* a **score function** (also known as *alignment score function* or *alignment model*). \n","\n","In this example, the *score function is* a **dot product** between the *decoder and encoder hidden states*.\n","\n","See [**Score Functions**](#score_functions) *for* a *variety of score functions*.\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/attention_mechanism1.gif\"/></center>\n","\n","<br>\n","\n","<center><strong>Fig. 1.1: Get the scores</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"VRO5akGgmx4m","colab_type":"raw"},"source":["```\n","decoder_hidden = [10, 5, 10]\n","\n","encoder_hidden      score\n","--------------------------\n","   [0, 1, 1]         15 (= 10×0 + 5×1 + 10×1, the dot product)\n","   [5, 0, 1]         60\n","   [1, 1, 0]         15\n","   [0, 5, 1]         35\n","```"]},{"cell_type":"markdown","metadata":{"id":"elKzNbSSmx4n","colab_type":"text"},"source":["In the above example, we *obtain* a **high attention score** of `60` for the *encoder hidden state* `[5, 0, 1]`. \n","\n","This *means that* the *next word to be translated* is going to be *heavily influenced by this encoder hidden state*.\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"Jw5fpP3imx4n","colab_type":"text"},"source":["**Step 2: Run all the scores through a softmax layer.**\n","\n","We put the *scores to* a **softmax layer** so that the *softmaxed scores* (*scalar*) *add up to* **1**. \n","\n","These *softmaxed scores represent* the ***attention distribution***.\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/attention_mechanism2.gif\"/></center>\n","\n","<br>\n","\n","<center><strong>Fig. 1.2: Get the softmaxed scores</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"yOGhCks-mx4o","colab_type":"raw"},"source":["```\n","encoder_hidden     score     score^\n","------------------------------------\n","   [0, 1, 1]        15         0\n","   [5, 0, 1]        60         1\n","   [1, 1, 0]        15         0\n","   [0, 5, 1]        35         0\n","```"]},{"cell_type":"markdown","metadata":{"id":"vspKNAKKmx4p","colab_type":"text"},"source":["Notice that *based on* the **softmaxed score** `score^`, the *distribution of attention* is *only placed on* `[5, 0, 1]` as expected. \n","\n","*In reality*, *these numbers* are *not binary but* a **floating point between 0 and 1**.\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"Kbdl372omx4p","colab_type":"text"},"source":["**Step 3**: **Multiply each encoder hidden state by its softmaxed score.**\n","\n","By *multiplying each encoder hidden state with* its *softmaxed score* (*scalar*), we *obtain* the ***alignment vector*** or the ***annotation vector***. \n","\n","This is exactly the mechanism where **alignment takes place**.\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/attention_mechanism3.gif\"/></center>\n","\n","<br>\n","\n","<center><strong>Fig. 1.3: Get the alignment vectors</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"2oVRY41wmx4q","colab_type":"raw"},"source":["```\n","encoder        score      score^      alignment\n","------------------------------------------------\n","[0, 1, 1]       15         0          [0, 0, 0]\n","[5, 0, 1]       60         1          [5, 0, 1]\n","[1, 1, 0]       15         0          [0, 0, 0]\n","[0, 5, 1]       35         0          [0, 0, 0]\n","```"]},{"cell_type":"markdown","metadata":{"id":"ZvgwoYPAmx4r","colab_type":"text"},"source":["Here we see that the *alignment for all encoder hidden states except* `[5, 0, 1]` are *reduced to 0 due to low attention scores*. \n","\n","This *means* we can expect that the *first translated word should match* the *input word with* the `[5, 0, 1]` **embedding**.\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"VI_33Etxmx4r","colab_type":"text"},"source":["**Step 4**: **Sum up the alignment vectors.**\n","\n","The *alignment vectors* are *summed up to produce* the ***context vector***. \n","\n","A **context vector** is *an aggregated information of* the *alignment vectors from* the *previous step*.\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/attention_mechanism4.gif\"/></center>\n","\n","<br>\n","\n","<center><strong>Fig. 1.4: Get the context vector</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"gXeAWoNGmx4s","colab_type":"raw"},"source":["```\n","encoder        score      score^      alignment\n","------------------------------------------------\n","[0, 1, 1]       15         0          [0, 0, 0]\n","[5, 0, 1]       60         1          [5, 0, 1]\n","[1, 1, 0]       15         0          [0, 0, 0]\n","[0, 5, 1]       35         0          [0, 0, 0]\n","\n","\n","context = [0+5+0+0, 0+0+0+0, 0+1+0+0] \n","        = [5, 0, 1]\n","```"]},{"cell_type":"markdown","metadata":{"id":"-6VJv0Tamx4s","colab_type":"text"},"source":["**Step 5**: **Feed the context vector into the decoder.**\n","\n","The *manner this is done depends on* the **architecture design**.\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/attention_mechanism5.gif\"/></center>\n","\n","<br>\n","\n","<center><strong>Fig. 1.5: Feed the context vector to decoder</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"ghPc7kH_mx4w","colab_type":"text"},"source":["**Here’s the entire animation**:\n","\n","<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/attention_mechanism6.gif\"/></center>\n","\n","<br>\n","\n","<center><strong>Fig. 1.6: Attention</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"BUHqJQsImx4x","colab_type":"text"},"source":["<a id=score_functions></a>\n","#### Score Functions"]},{"cell_type":"markdown","metadata":{"id":"X6nFR1EQmx4x","colab_type":"text"},"source":["Below are *some* of the **score functions**. \n","\n","The *idea* behind *score functions* involving the **dot product operation** (*dot product*, *cosine similarity* etc.), is *to measure* the **similarity between two vectors**. \n","\n","For **feed-forward neural network score functions**, the *idea* is to *let the model learn* the *alignment weights together with* the **translation**."]},{"cell_type":"markdown","metadata":{"id":"PQX-Rzczmx4y","colab_type":"text"},"source":["<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/summary_score_functions.png\"/></center>\n","\n","<br>\n","\n","<center><strong>Summary of Score Functions</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"Isc_jmrTmx4z","colab_type":"text"},"source":["<br> \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/summary_score_functions1.png\"/></center>\n","\n","<br>\n","\n","<center><strong>Summary of Score Functions.</strong></center>\n","<center><strong>h represents encoder hidden states while s represents decoder hidden states.</strong></center>\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"n8cpfywjmx4z","colab_type":"text"},"source":["**Note:** The **Implementing Attention Mechanism** section in this notebook is *inspired from* the **Towards Data Science** article **Attn: Illustrated Attention** written by **Raimi Karim**."]},{"cell_type":"markdown","metadata":{"id":"3CQJGpwKmx40","colab_type":"text"},"source":["<a id=section4></a>\n","## 4. Conclusion"]},{"cell_type":"markdown","metadata":{"id":"biFFcBTQmx41","colab_type":"text"},"source":["The **Attention mechanism** has *revolutionised* the *way we create NLP models* and is currently a **standard fixture** in *most state-of-the-art NLP models*. \n","\n","This is *because it enables* the *model to “**remember**” all* the *words in* the **input** and *focus on specific words when formulating a response*.\n","\n","A big **advantage of attention** is that *it gives* us the **ability to interpret** and **visualize** what the *model is doing*. \n","\n","For example, *by visualizing* the **attention weight matrix $\\alpha$** *when a sentence is translated*, we *can understand how* the *model is translating*."]}]}